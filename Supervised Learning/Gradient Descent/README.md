# Gradient Descent
Gradient descent is a popular optimization approach for training machine learning models and neural networks. These models evolve over time with the use of training data, and the cost function inside gradient descent especially functions as a barometer, assessing its correctness with each iteration of parameter changes. The model will continue to change its parameters until the function is near to or equal to zero, at which point it will stop. The purpose of gradient descent, like finding the line of best fit in linear regression, is to minimize the cost function, or the difference between expected and actual.

## Dataset

## Task
